{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help Twitter Combat Hate Speech Using NLP and Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all Important and needed liabraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('English')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load the tweets file using read_csv function from Pandas package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/91805/Documents/Kalpesh Mahajan/Natuaral Language Processing Class/Project 1  Help Twitter Combat Hate Speech Using NLP and Machine Learning/TwitterHate.csv'\n",
    "TweetData = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the first few records.\n",
    "TweetData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "TweetData.shape\n",
    "# Total No of Rows = 31962\n",
    "# Total No of Columns = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       False\n",
       "label    False\n",
       "tweet    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Null Values of any\n",
    "TweetData.isnull().any()\n",
    "# Conclusion there is no column with null values in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n",
      "None\n",
      "------------------Check Duplicate Entries in each coumns--------------------------\n",
      "Unique entries in id: 31962\n",
      "Unique entries in label: 31962\n",
      "Unique entries in tweet: 31962\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the Attributes or MetaData of the Data.\n",
    "print(TweetData.info())\n",
    "print('------------------Check Duplicate Entries in each coumns--------------------------')\n",
    "print('Unique entries in id:',TweetData.id.value_counts().sum())\n",
    "print('Unique entries in label:',TweetData.label.value_counts().sum())\n",
    "print('Unique entries in tweet:',TweetData.tweet.value_counts().sum())\n",
    "print('-----------------------------------------------------------------------------------')\n",
    "# Conclusions:\n",
    "# 1. Id column is having Data type int and no null values.\n",
    "# 2. label column is having Data type int and no null values\n",
    "# 3. tweet column is having Data type object and no null values.\n",
    "# 4. There are no missing values in any column\n",
    "# 5. There are no duplicate entries in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label\n",
      "0  29720\n",
      "1   2242\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x237ef8c4e88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the categerories \n",
    "PieData = pd.DataFrame(TweetData.label.value_counts())\n",
    "print(PieData)\n",
    "\n",
    "#=========================================Check using pie Plot====================================================\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(PieData,labels=['non hate','hate'])\n",
    "plt.title(\"Total Hate and Non Values classification\")\n",
    "plt.show()\n",
    "\n",
    "#=========================================Check using Bar Plot====================================================\n",
    "PieData[\"categeory\"] = pd.Series(['non hate','hate'])\n",
    "sns.barplot(x='categeory',y='label',data=PieData)\n",
    "# Conclusion : The output is imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function cleanup will perform below tasks.\n",
    "1. Convert all the words into lowercase\n",
    "2. Remove the redundant workd 'rt' from data\n",
    "3. Remove the redundant word 'amp' from data\n",
    "4. Remove the user handles starting with @ and sometimes ending with colan.\n",
    "5. Remove the '#' tags from the data.\n",
    "6. Remove all the punctuations.\n",
    "7. Remove repeated special characters from the text.\n",
    "8. Perfrom Tokenization.\n",
    "9. Perform Stemming of the words and remove the stopwords.\n",
    "10. Remove the words with length 1\n",
    "11. Only return the alphabetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    \n",
    "    # Make all words in lower case\n",
    "    text = [word.lower() for word in text]\n",
    "    \n",
    "    # Remove redundant term rt \n",
    "    OperationA = [re.sub(r'^rt',' ',tweet) for tweet in text]\n",
    "    \n",
    "    # Remove reduadant term amp from the text \n",
    "    OperationB = [re.sub(r'amp',' ',tweet) for tweet in OperationA]\n",
    "    \n",
    "    #User Handle Removed\n",
    "    Operation1 = [re.sub('@\\w+|@w+:','',words) for words in OperationB]\n",
    "    \n",
    "    # Remove '#' tag from the text and retain the word.\n",
    "    Operation2 = [re.sub('#',' ',words) for words in Operation1]\n",
    "    \n",
    "   \n",
    "    # Remove URLs from the text\n",
    "    Operation3 = [re.sub('http:\\/\\/\\w.+|https:\\/\\/\\w.+','',words) for words in Operation2]\n",
    "    \n",
    "    #Remove Repeated Special Characters from the text.\n",
    "    \n",
    "    Operation4 = [re.sub('[\\\\,--,!+,*,..,:]+','',words) for words in Operation3]\n",
    "    \n",
    "    # Remove the Punctuations from the text\n",
    "    Operation5 = \"\".join([word.lower() for word in Operation4 if word not in string.punctuation])\n",
    "    \n",
    "   \n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(Operation5)\n",
    "    \n",
    "    # Stem the words and Remove the stopwords.\n",
    "    Operation6 = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    \n",
    "    # Remove the words with Lengh 1\n",
    "    Operation7 = [word for word in Operation6 if len(word) > 1 ]\n",
    "    \n",
    "    # Consider only Aplphabetic words \n",
    "    \n",
    "    Operation8 = [word for word in Operation7 if str(word).isalpha() is True]\n",
    "    return(Operation8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering using TD-IDF vectorizer to find 10 most common terms used in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the counter and find the 10 most common terms.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "TF_IDF_Vec = TfidfVectorizer(analyzer=cleanup,max_features=10)\n",
    "X_tfidf1 = TF_IDF_Vec.fit_transform(TweetData.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amp', 'day', 'get', 'go', 'happi', 'im', 'love', 'thank', 'time', 'user']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and print 10 most common test.\n",
    "\n",
    "Top10MostCommonTerms = TF_IDF_Vec.get_feature_names()\n",
    "Top10MostCommonTerms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X Data using TFIDF vectorizer.\n",
    "\n",
    "TF_IDF_Vec1 = TfidfVectorizer(analyzer=cleanup,max_features=5000)\n",
    "X_Final = TF_IDF_Vec1.fit_transform(TweetData.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the X Features\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "XFeatures = pd.DataFrame(X_Final.toarray())\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(XFeatures,TweetData.label,random_state = 123,train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569, 5000) (6393, 5000) (25569,) (6393,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Score :0.9554199906147348 Train Score: 0.9549845516054597 for random state: 17\n",
      " Test Score :0.9565149382136712 Train Score: 0.9545934530095037 for random state: 49\n",
      " Test Score :0.9544814641013608 Train Score: 0.9543587938519301 for random state: 70\n"
     ]
    }
   ],
   "source": [
    "# This step will help finding us Generalized model.\n",
    "# We will be able to find the Random state value which is generating the Test Score of the model greater than Train Score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "for i in range(1,100):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(XFeatures,TweetData.label,random_state = i,train_size = 0.8)\n",
    "\n",
    "    Log_reg_model = LogisticRegression(random_state=1)\n",
    "    Log_reg_model.fit(X_train,y_train)\n",
    "\n",
    "    Log_reg_train_score = Log_reg_model.score(X_train,y_train)\n",
    "    Log_reg_test_score  = Log_reg_model.score(X_test,y_test)\n",
    "    \n",
    "    if Log_reg_test_score > Log_reg_train_score:\n",
    "        print (\" Test Score :{} Train Score: {} for random state: {}\".format(Log_reg_test_score,Log_reg_train_score,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Reg Train Score: 0.9543587938519301\n",
      "Log Reg Test Score: 0.9544814641013608\n"
     ]
    }
   ],
   "source": [
    "# Perfrom Train Test Split with random state found in above step.\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(XFeatures,TweetData.label,random_state = 70,train_size = 0.8)\n",
    "Log_reg_model = LogisticRegression(random_state=1)\n",
    "Log_reg_model.fit(X_train,y_train)\n",
    "\n",
    "Log_reg_train_score = Log_reg_model.score(X_train,y_train)\n",
    "Log_reg_test_score  = Log_reg_model.score(X_test,y_test)\n",
    "\n",
    "Log_reg_y_pred_test = Log_reg_model.predict(X_test)\n",
    "Log_reg_y_pred_train = Log_reg_model.predict(X_train)\n",
    "\n",
    "print(\"Log Reg Train Score:\",Log_reg_train_score)\n",
    "print(\"Log Reg Test Score:\", Log_reg_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Confusion Matrics and Classification Report for Test Data====================================\n",
      "[[5948   11]\n",
      " [ 280  154]]\n",
      "=================================================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5959\n",
      "           1       0.93      0.35      0.51       434\n",
      "\n",
      "    accuracy                           0.95      6393\n",
      "   macro avg       0.94      0.68      0.75      6393\n",
      "weighted avg       0.95      0.95      0.94      6393\n",
      "\n",
      "====================Confusion Matrics and Classification Report for Train Data====================================\n",
      "[[23722    39]\n",
      " [ 1128   680]]\n",
      "=================================================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     23761\n",
      "           1       0.95      0.38      0.54      1808\n",
      "\n",
      "    accuracy                           0.95     25569\n",
      "   macro avg       0.95      0.69      0.76     25569\n",
      "weighted avg       0.95      0.95      0.95     25569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets Evaluate the model using confusion Matrix and Classification Report.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"====================Confusion Matrics and Classification Report for Test Data====================================\")\n",
    "print(confusion_matrix(y_test,Log_reg_y_pred_test))\n",
    "print(\"=================================================================================================================\")\n",
    "print(classification_report(y_test,Log_reg_y_pred_test))\n",
    "print(\"====================Confusion Matrics and Classification Report for Train Data====================================\")\n",
    "print(confusion_matrix(y_train,Log_reg_y_pred_train))\n",
    "print(\"=================================================================================================================\")\n",
    "print(classification_report(y_train,Log_reg_y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions.\n",
    "1. We have Train Score of 0.95\n",
    "2. We have Test Score of 0.96\n",
    "3. We have Test Score > Train score hence we have generalized model\n",
    "\n",
    "Although we have generalized model as this is case of class imbalance we need to adjust class imbalance using SMOT as below and try to find best model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adjusting class imbalance with SMOT and build model using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "#?SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote1 = SMOTE(random_state=42)\n",
    "#XSM_train,XSM_test = smote1.fit_sample(X_train,y_train)\n",
    "#(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res,y_res = smote1.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Before Sampling Shape======================\n",
      "(25569, 5000) (25569,)\n",
      "23761\n",
      "1808\n",
      "=================After Sampling Shape======================\n",
      "(47522, 5000) (47522,)\n",
      "23761\n",
      "23761\n"
     ]
    }
   ],
   "source": [
    "print('=================Before Sampling Shape======================')\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(sum(y_train==0))\n",
    "print(sum(y_train==1))\n",
    "print('=================After Sampling Shape======================')\n",
    "print(X_res.shape,y_res.shape)\n",
    "print(sum(y_res==0))\n",
    "print(sum(y_res==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Reg Train Score: 0.9586296873027229\n",
      "Log Reg Test Score: 0.904895979978101\n"
     ]
    }
   ],
   "source": [
    "# Train the model once again with new Training samples.\n",
    "\n",
    "\n",
    "Log_reg_model_res = LogisticRegression(random_state=1)\n",
    "Log_reg_model_res.fit(X_res,y_res)\n",
    "\n",
    "Log_reg_train_score_res = Log_reg_model_res.score(X_res,y_res)\n",
    "Log_reg_test_score_res  = Log_reg_model_res.score(X_test,y_test)\n",
    "\n",
    "Log_reg_y_pred_test_res = Log_reg_model_res.predict(X_test)\n",
    "Log_reg_y_pred_train_res = Log_reg_model_res.predict(X_res)\n",
    "    \n",
    "print(\"Log Reg Train Score:\",Log_reg_train_score_res)\n",
    "print(\"Log Reg Test Score:\", Log_reg_test_score_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Confusion Matrics and Classification Report for Test Data====================================\n",
      "[[5948   11]\n",
      " [ 280  154]]\n",
      "=================================================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5959\n",
      "           1       0.93      0.35      0.51       434\n",
      "\n",
      "    accuracy                           0.95      6393\n",
      "   macro avg       0.94      0.68      0.75      6393\n",
      "weighted avg       0.95      0.95      0.94      6393\n",
      "\n",
      "====================Confusion Matrics and Classification Report for Test Data====================================\n",
      "[[22264  1497]\n",
      " [  469 23292]]\n",
      "=================================================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96     23761\n",
      "           1       0.94      0.98      0.96     23761\n",
      "\n",
      "    accuracy                           0.96     47522\n",
      "   macro avg       0.96      0.96      0.96     47522\n",
      "weighted avg       0.96      0.96      0.96     47522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets evaluate the model using Classification report and confusion matrix.\n",
    "\n",
    "print(\"====================Confusion Matrics and Classification Report for Test Data====================================\")\n",
    "print(confusion_matrix(y_test,Log_reg_y_pred_test))\n",
    "print(\"=================================================================================================================\")\n",
    "print(classification_report(y_test,Log_reg_y_pred_test))\n",
    "print(\"====================Confusion Matrics and Classification Report for Test Data====================================\")\n",
    "print(confusion_matrix(y_res,Log_reg_y_pred_train_res))\n",
    "print(\"=================================================================================================================\")\n",
    "print(classification_report(y_res,Log_reg_y_pred_train_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Try finding out Better model using Cross Valuation Score and Stratified K fold split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the class is imbalanced we need to use Startified K fold spit before we go ahed with Hyperparameter Tuning.\n",
    "\n",
    "Label 0 Count :   29720\n",
    "Label 1 Count :   2242\n",
    "\n",
    "We will perform below steps to try finding better model handling class imbalance.\n",
    "\n",
    "1. Cross Val Score : try finding out the logistic regression model with cross val score with sample split of 10.Try getting min ,max and average accuracy scores using the Cross Val Score.\n",
    "\n",
    "2. Stratified K fold Split : We will use the Stratified K fold split to find out best train test set which is giving Generalized model with accuracy score greater than average accuracy score. \n",
    "\n",
    "3. Train and Test the Logistic Regression Model : This step will train and test the Logistic regression model using best train and test split we have obtained in step 2.\n",
    "\n",
    "4. Evaluate the model : We will finally evaluate the model using confusion matrics and classificaiotn report to check accuracy score , F1 socre and other parameters and also see if we have got the generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Featues and Class Labels into X and Y respectively for further processing. The format Numpy is specifically used in order to\n",
    "# perform faster processing.\n",
    "\n",
    "Y = TweetData.label.to_numpy()\n",
    "X= XFeatures.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Results obtained using CV=10 : 0.9489987484355444\n",
      "Average Accuracy obtained using CV=10: 0.9516926949271513\n",
      "Maximum Accuracy obtained using CV=10: 0.9565081351689612\n",
      "--------------------------------------------------------\n",
      "[0.95120425 0.95026587 0.95025031 0.95650814 0.95400501 0.95275344\n",
      " 0.94899875 0.95118899 0.95118899 0.9505632 ]\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=1)\n",
    "\n",
    "results = cross_val_score(LR,X,Y,cv=10)\n",
    "print('Minimum Results obtained using CV=10 :',np.min(results))\n",
    "print('Average Accuracy obtained using CV=10:',np.mean(results))\n",
    "print('Maximum Accuracy obtained using CV=10:',np.max(results))\n",
    "print('--------------------------------------------------------')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score : 0.9533792240300375 Train Score : 0.9565111590071612 for Sample Split :3 : \n",
      "Test Score : 0.9530663329161452 Train Score : 0.9565806855315303 for Sample Split :5 : \n",
      "Test Score : 0.9518147684605757 Train Score : 0.9572411875130362 for Sample Split :7 : \n",
      "Test Score : 0.9540050062578223 Train Score : 0.9566502120558993 for Sample Split :8 : \n",
      "Test Score : 0.9524405506883604 Train Score : 0.9569978446777445 for Sample Split :9 : \n",
      "Test Score : 0.9518147684605757 Train Score : 0.9564068692206077 for Sample Split :10 : \n"
     ]
    }
   ],
   "source": [
    "# lets Apply the stratified K fold split to get best train test split preserving the Class balance.\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "SKF = StratifiedKFold(n_splits=10,random_state=1, shuffle=True)\n",
    "\n",
    "i=0\n",
    "for train_index,test_index in SKF.split(X,Y):\n",
    "    i=i+1 # Increate the counter with every iterations.\n",
    "     \n",
    "    X_train_SKF,X_test_SKF = X[train_index],X[test_index]\n",
    "    y_train_SKF,y_test_SKF = Y[train_index],Y[test_index]\n",
    "    \n",
    "    LR.fit(X_train_SKF,y_train_SKF)\n",
    "    \n",
    "    #y_pred_SKF = LR.predict(y_test_SKF)\n",
    "    \n",
    "    if LR.score(X_test_SKF,y_test_SKF) > 0.9516926949271513:\n",
    "        print('Test Score : {} Train Score : {} for Sample Split :{} : '.format(LR.score(X_test_SKF,y_test_SKF),\n",
    "                                                                               LR.score(X_train_SKF,y_train_SKF),i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "\n",
    "1. From Above its clear that we still do not have true generalized model having Test score greater than Train Score.\n",
    "2. The best train test sample cab be obtained for CV=8\n",
    "3. In below step we will build the final Model with best Train test sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================MODEL SCORES =========================================\n",
      "Test Score : 0.9540050062578223 Train Score 0.9566502120558993 \n",
      "==========================CONFUSION MATRICS=====================================\n",
      "[[2966    6]\n",
      " [ 141   83]]\n",
      "==========================CLASSIFICATION REPORT=================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2972\n",
      "           1       0.93      0.37      0.53       224\n",
      "\n",
      "    accuracy                           0.95      3196\n",
      "   macro avg       0.94      0.68      0.75      3196\n",
      "weighted avg       0.95      0.95      0.94      3196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Final model using best training and testing samples.\n",
    "\n",
    "# Initializs the Stratified K fold split.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "SKF = StratifiedKFold(n_splits=10,random_state=1, shuffle=True)\n",
    "\n",
    "# Below for loop will pick the Train Test split for Split value 8 as we had good test score from above step results \n",
    "# for shuffle split 8\n",
    "\n",
    "i=0\n",
    "for train_index,test_index in SKF.split(X,Y):\n",
    "    i=i+1 # Increate the counter with every iterations.\n",
    "     \n",
    "    X_train_SKF,X_test_SKF = X[train_index],X[test_index]\n",
    "    y_train_SKF,y_test_SKF = Y[train_index],Y[test_index]\n",
    "    \n",
    "    LR.fit(X_train_SKF,y_train_SKF)\n",
    "    \n",
    "     # Get the values into Final Variables.\n",
    "    if i == 8:\n",
    "        X_train_final = X_train_SKF\n",
    "        X_test_final  = X_test_SKF\n",
    "        y_train_final = y_train_SKF\n",
    "        y_test_final  = y_test_SKF\n",
    "\n",
    "# Fit the model on best Training samples.\n",
    "\n",
    "LR.fit(X_train_final,y_train_final)\n",
    "\n",
    "# Print the score for info purpose.\n",
    "print('==========================MODEL SCORES =========================================')\n",
    "print ('Test Score : {} Train Score {} '.format(LR.score(X_test_final,y_test_final),LR.score(X_train_final,y_train_final)))\n",
    "\n",
    "# Predict the value\n",
    "\n",
    "y_pred_final=LR.predict(X_test_final)\n",
    "\n",
    "print('==========================CONFUSION MATRICS=====================================')\n",
    "print(confusion_matrix(y_test_final,y_pred_final))\n",
    "print('==========================CLASSIFICATION REPORT=================================')\n",
    "print(classification_report(y_test_final,y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: We still don't have the generalized model. Lets try improving the accuracy score using hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Hyperparameter Tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  28 | elapsed: 18.7min remaining:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed: 22.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=LogisticRegression(random_state=1), n_jobs=-1,\n",
       "             param_grid=[{'penalty': ['l2'],\n",
       "                          'solver': ['newton-cg', 'lbfgs', 'sag']},\n",
       "                         {'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['liblinear', 'saga']}],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tunning for the model.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the Parameter Grid using Dictionary Object.\n",
    "ParameterGrid = [ {'penalty': ['l2'],'solver': ['newton-cg','lbfgs','sag']} ,\n",
    "                 {'penalty': ['l1','l2'],'solver':['liblinear','saga']} ]\n",
    "               \n",
    "# Create GridSearchCV Object.\n",
    "\n",
    "GSCV = GridSearchCV(LR,ParameterGrid,n_jobs=-1,cv=4,verbose=3)\n",
    "\n",
    "# Fit the GridSearch CV on X and Y variables.\n",
    "\n",
    "GSCV.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', random_state=1, solver='liblinear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================Model Score======================================================\n",
      "0.9638946248670296\n",
      "==========================================Confusion Matrics================================================\n",
      "[[29608   112]\n",
      " [ 1042  1200]]\n",
      "==========================================Classification Report============================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     29720\n",
      "           1       0.91      0.54      0.68      2242\n",
      "\n",
      "    accuracy                           0.96     31962\n",
      "   macro avg       0.94      0.77      0.83     31962\n",
      "weighted avg       0.96      0.96      0.96     31962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets use the parameters we have got above and play with Parameter C.\n",
    "\n",
    "FinalLogReg = LogisticRegression(penalty='l1', random_state=1, solver='liblinear')\n",
    "FinalLogReg.fit(X,Y)\n",
    "\n",
    "# Print the model Score.\n",
    "print('==========================================Model Score======================================================')\n",
    "print(FinalLogReg.score(X,Y))\n",
    "\n",
    "# Predict the Y value based on X values with Final Model.\n",
    "y_pred_final_Hyp = FinalLogReg.predict(X)\n",
    "\n",
    "# Confusion Matrics.\n",
    "print('==========================================Confusion Matrics================================================')\n",
    "print(confusion_matrix(Y,y_pred_final_Hyp))\n",
    "# Classification Report.\n",
    "print('==========================================Classification Report============================================')\n",
    "print(classification_report(Y,y_pred_final_Hyp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Conclusion of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "    1. With the final model we have got the accuracy score of 96.\n",
    "    2. The recall value of class '1' has been also improved to 0.54 which was below 0.40 for other old models.\n",
    "    3. The F1 Score has also improved to 0.68 from 0.53 and below for other models\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with a sample Tweet\n",
    "\n",
    "Lets Test the model with sample input. The input tweet is taken from input data only for which the label is already available.\n",
    "\n",
    "Testing Tweets are as below : \n",
    "\n",
    "\n",
    "Record no 3,Tweet - \"i get to see my daddy today!!   #80days #gettingfed\" , Label = 0(non-hate)\n",
    "\n",
    "\n",
    "Record no 363,Tweet - \"trump ny co-chair makes racist remarks about michelle obama  #p2 #p21 #fyi  #tcot\", Label = 1 (hate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Tweet :i get to see my daddy today!! #80days #gettingfed\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "You have entered the Tweet :\" i get to see my daddy today!! #80days #gettingfed \"\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "The model returned lable value is: [0]\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "The Tweet is non hate Tweet\n"
     ]
    }
   ],
   "source": [
    "# Accept the input from the User\n",
    "# Test Case : Non Hate Tweet.\n",
    "TestTweet = input(\"Enter the Tweet :\")\n",
    "\n",
    "# Display the accepted input to the user.\n",
    "print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"You have entered the Tweet :\"'\"',TestTweet,'\"')\n",
    "TestTweetDF = pd.DataFrame(pd.Series(TestTweet))\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# Perform cleaning and conversion into TF-IDF features.\n",
    "\n",
    "TF_IDF_VecTest = TfidfVectorizer(analyzer=cleanup,max_features=5000)\n",
    "XUserTest = TF_IDF_Vec1.transform(TestTweetDF.iloc[:,0])\n",
    "XUserFeatureTest = pd.DataFrame(XUserTest.toarray())\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"The model returned lable value is:\",FinalLogReg.predict(XUserFeatureTest))\n",
    "print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "if FinalLogReg.predict(XUserFeatureTest) == 0:\n",
    "    print(\"The Tweet is non hate Tweet\")\n",
    "else:\n",
    "    print(\"The Tweet is hate Tweet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Tweet :trump ny co-chair makes racist remarks about michelle obama #p2 #p21 #fyi #tcot\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "You have entered the Tweet :\" trump ny co-chair makes racist remarks about michelle obama #p2 #p21 #fyi #tcot \"\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "The model returned lable value is: [1]\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "The Tweet is hate Tweet\n"
     ]
    }
   ],
   "source": [
    "# Accept the input from the User\n",
    "# Test Case : Hate Tweet.\n",
    "TestTweet = input(\"Enter the Tweet :\")\n",
    "\n",
    "# Display the accepted input to the user.\n",
    "print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"You have entered the Tweet :\"'\"',TestTweet,'\"')\n",
    "TestTweetDF = pd.DataFrame(pd.Series(TestTweet))\n",
    "print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# Perform cleaning and conversion into TF-IDF features.\n",
    "\n",
    "TF_IDF_VecTest = TfidfVectorizer(analyzer=cleanup,max_features=5000)\n",
    "XUserTest = TF_IDF_Vec1.transform(TestTweetDF.iloc[:,0])\n",
    "XUserFeatureTest = pd.DataFrame(XUserTest.toarray())\n",
    "print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"The model returned lable value is:\",FinalLogReg.predict(XUserFeatureTest))\n",
    "print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "if FinalLogReg.predict(XUserFeatureTest) == 0:\n",
    "    print(\"The Tweet is non hate Tweet\")\n",
    "else:\n",
    "    print(\"The Tweet is hate Tweet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model using pickle.\n",
    "import pickle\n",
    "filename = 'twitterhatemodel'\n",
    "outfil = open(filename,'wb')\n",
    "pickle.dump(TF_IDF_Vec1,outfil)\n",
    "pickle.dump(FinalLogReg,outfil)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
